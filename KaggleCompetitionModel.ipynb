{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d85cb5c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-08-01T07:14:30.444209Z",
     "iopub.status.busy": "2021-08-01T07:14:30.443471Z",
     "iopub.status.idle": "2021-08-01T07:14:30.448613Z",
     "shell.execute_reply": "2021-08-01T07:14:30.449295Z",
     "shell.execute_reply.started": "2021-08-01T07:07:32.898543Z"
    },
    "papermill": {
     "duration": 0.02806,
     "end_time": "2021-08-01T07:14:30.449638",
     "exception": false,
     "start_time": "2021-08-01T07:14:30.421578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/commonlitreadabilityprize/sample_submission.csv\n",
      "/kaggle/input/commonlitreadabilityprize/train.csv\n",
      "/kaggle/input/commonlitreadabilityprize/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36e154d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T07:14:30.478329Z",
     "iopub.status.busy": "2021-08-01T07:14:30.477622Z",
     "iopub.status.idle": "2021-08-01T07:14:30.677637Z",
     "shell.execute_reply": "2021-08-01T07:14:30.678085Z",
     "shell.execute_reply.started": "2021-08-01T07:07:32.911076Z"
    },
    "papermill": {
     "duration": 0.216131,
     "end_time": "2021-08-01T07:14:30.678272",
     "exception": false,
     "start_time": "2021-08-01T07:14:30.462141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85aa80a4c</td>\n",
       "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
       "      <td>-0.315372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b69ac6792</td>\n",
       "      <td>As Roger had predicted, the snow departed as q...</td>\n",
       "      <td>-0.580118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            excerpt    target\n",
       "0  c12129c31  When the young people returned to the ballroom... -0.340259\n",
       "1  85aa80a4c  All through dinner time, Mrs. Fayre was somewh... -0.315372\n",
       "2  b69ac6792  As Roger had predicted, the snow departed as q... -0.580118"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/commonlitreadabilityprize/train.csv')\n",
    "train_data.drop(['url_legal', 'license', 'standard_error'], axis=1, inplace=True)\n",
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e9d1ca8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T07:14:30.706953Z",
     "iopub.status.busy": "2021-08-01T07:14:30.706224Z",
     "iopub.status.idle": "2021-08-01T07:14:30.724728Z",
     "shell.execute_reply": "2021-08-01T07:14:30.724198Z",
     "shell.execute_reply.started": "2021-08-01T07:07:32.974724Z"
    },
    "papermill": {
     "duration": 0.034702,
     "end_time": "2021-08-01T07:14:30.724879",
     "exception": false,
     "start_time": "2021-08-01T07:14:30.690177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>excerpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f722661</td>\n",
       "      <td>My hope lay in Jack's promise that he would ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f0953f0a5</td>\n",
       "      <td>Dotty continued to go to Mrs. Gray's every nig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0df072751</td>\n",
       "      <td>It was a bright and cheerful scene that greete...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            excerpt\n",
       "0  c0f722661  My hope lay in Jack's promise that he would ke...\n",
       "1  f0953f0a5  Dotty continued to go to Mrs. Gray's every nig...\n",
       "2  0df072751  It was a bright and cheerful scene that greete..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('/kaggle/input/commonlitreadabilityprize/test.csv')\n",
    "test_data.drop(['url_legal', 'license'], axis=1, inplace=True)\n",
    "test_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a7d32d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T07:14:30.753948Z",
     "iopub.status.busy": "2021-08-01T07:14:30.753145Z",
     "iopub.status.idle": "2021-08-01T07:14:30.756887Z",
     "shell.execute_reply": "2021-08-01T07:14:30.756257Z",
     "shell.execute_reply.started": "2021-08-01T07:07:32.992168Z"
    },
    "papermill": {
     "duration": 0.020229,
     "end_time": "2021-08-01T07:14:30.757028",
     "exception": false,
     "start_time": "2021-08-01T07:14:30.736799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define X, y and test\n",
    "X_train = train_data.excerpt\n",
    "Y_train = train_data.target\n",
    "final_test = test_data.excerpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72d4d8e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T07:14:30.786974Z",
     "iopub.status.busy": "2021-08-01T07:14:30.786208Z",
     "iopub.status.idle": "2021-08-01T07:14:31.811951Z",
     "shell.execute_reply": "2021-08-01T07:14:31.811400Z",
     "shell.execute_reply.started": "2021-08-01T07:07:32.997925Z"
    },
    "papermill": {
     "duration": 1.043277,
     "end_time": "2021-08-01T07:14:31.812110",
     "exception": false,
     "start_time": "2021-08-01T07:14:30.768833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.20, random_state=42)\n",
    "x_train = np.array(x_train)\n",
    "x_val = np.array(x_val)\n",
    "y_train = np.array(y_train) #y_train\n",
    "y_val = np.array(y_val) #y_test\n",
    "final_test = np.array(final_test)\n",
    "X_full = np.array(X_train)\n",
    "Y_full = np.array(Y_train) #y_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd4e61d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T07:14:31.842070Z",
     "iopub.status.busy": "2021-08-01T07:14:31.841418Z",
     "iopub.status.idle": "2021-08-01T07:14:32.933190Z",
     "shell.execute_reply": "2021-08-01T07:14:32.932314Z",
     "shell.execute_reply.started": "2021-08-01T07:07:33.015689Z"
    },
    "papermill": {
     "duration": 1.109313,
     "end_time": "2021-08-01T07:14:32.933386",
     "exception": false,
     "start_time": "2021-08-01T07:14:31.824073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2267, 100) (2267,)\n",
      "(567, 100) (567,)\n",
      "(7, 100)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(lowercase=True, stop_words='english',max_features=100,strip_accents='unicode')\n",
    "x_train_vector = vectorizer.fit_transform (x_train).toarray() #train_vector\n",
    "x_val_vector = vectorizer.fit_transform (x_val).toarray() #test_vectors\n",
    "x_full = vectorizer.fit_transform (X_full).toarray() #vectors_full\n",
    "final_test_vector = vectorizer.transform (final_test).toarray() #real_test_vectors\n",
    "print(x_train_vector.shape, y_train.shape)\n",
    "print(x_val_vector.shape, y_val.shape)\n",
    "print(final_test_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "855d510d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T07:14:32.975021Z",
     "iopub.status.busy": "2021-08-01T07:14:32.973826Z",
     "iopub.status.idle": "2021-08-01T07:14:38.502351Z",
     "shell.execute_reply": "2021-08-01T07:14:38.501817Z",
     "shell.execute_reply.started": "2021-08-01T07:07:34.463327Z"
    },
    "papermill": {
     "duration": 5.54951,
     "end_time": "2021-08-01T07:14:38.502563",
     "exception": false,
     "start_time": "2021-08-01T07:14:32.953053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e695ce6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T07:14:38.534749Z",
     "iopub.status.busy": "2021-08-01T07:14:38.533789Z",
     "iopub.status.idle": "2021-08-01T07:14:38.536058Z",
     "shell.execute_reply": "2021-08-01T07:14:38.536435Z",
     "shell.execute_reply.started": "2021-08-01T07:07:34.471464Z"
    },
    "papermill": {
     "duration": 0.021922,
     "end_time": "2021-08-01T07:14:38.536634",
     "exception": false,
     "start_time": "2021-08-01T07:14:38.514712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(units=512, kernel_initializer='normal', activation='relu', input_shape=[100]),\n",
    "        layers.Dense(units=256, kernel_initializer='normal', activation='relu'),\n",
    "        layers.Dense(units=128, kernel_initializer='normal', activation='relu'),\n",
    "        layers.Dropout(0.25),\n",
    "        # the linear output layer \n",
    "        layers.Dense(units=1, kernel_initializer='normal', activation='linear'),\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer = 'adam', loss='mean_squared_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b6cd88f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T07:14:38.566171Z",
     "iopub.status.busy": "2021-08-01T07:14:38.565480Z",
     "iopub.status.idle": "2021-08-01T07:17:31.706619Z",
     "shell.execute_reply": "2021-08-01T07:17:31.706039Z",
     "shell.execute_reply.started": "2021-08-01T07:07:34.485849Z"
    },
    "papermill": {
     "duration": 173.158486,
     "end_time": "2021-08-01T07:17:31.706775",
     "exception": false,
     "start_time": "2021-08-01T07:14:38.548289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "160/160 [==============================] - 1s 2ms/step - loss: 1.1596\n",
      "Epoch 2/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.7820\n",
      "Epoch 3/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.6804\n",
      "Epoch 4/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.5063\n",
      "Epoch 5/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.3750\n",
      "Epoch 6/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.2621\n",
      "Epoch 7/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.2117\n",
      "Epoch 8/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1461\n",
      "Epoch 9/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1137\n",
      "Epoch 10/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0889\n",
      "Epoch 11/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0907\n",
      "Epoch 12/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0733\n",
      "Epoch 13/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0703\n",
      "Epoch 14/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0662\n",
      "Epoch 15/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0611\n",
      "Epoch 16/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0628\n",
      "Epoch 17/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0658\n",
      "Epoch 18/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0641\n",
      "Epoch 19/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0702\n",
      "Epoch 20/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0575\n",
      "Epoch 21/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0547\n",
      "Epoch 22/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0579\n",
      "Epoch 23/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0543\n",
      "Epoch 24/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0509\n",
      "Epoch 25/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0549\n",
      "Epoch 26/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0459\n",
      "Epoch 27/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0463\n",
      "Epoch 28/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0498\n",
      "Epoch 29/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0498\n",
      "Epoch 30/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0500\n",
      "Epoch 31/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0505\n",
      "Epoch 32/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0478\n",
      "Epoch 33/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0476\n",
      "Epoch 34/50\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0499\n",
      "Epoch 35/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0426\n",
      "Epoch 36/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0459\n",
      "Epoch 37/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0444\n",
      "Epoch 38/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0394\n",
      "Epoch 39/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0408\n",
      "Epoch 40/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0431\n",
      "Epoch 41/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0438\n",
      "Epoch 42/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0456\n",
      "Epoch 43/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0418\n",
      "Epoch 44/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0423\n",
      "Epoch 45/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0388\n",
      "Epoch 46/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0378\n",
      "Epoch 47/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0394\n",
      "Epoch 48/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0393\n",
      "Epoch 49/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0353\n",
      "Epoch 50/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0342\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.8090\n",
      "Epoch 1/50\n",
      "160/160 [==============================] - 1s 2ms/step - loss: 1.0643\n",
      "Epoch 2/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.7293\n",
      "Epoch 3/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.5905\n",
      "Epoch 4/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.4667\n",
      "Epoch 5/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.3355\n",
      "Epoch 6/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.2172\n",
      "Epoch 7/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1556\n",
      "Epoch 8/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1284\n",
      "Epoch 9/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1086\n",
      "Epoch 10/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0855\n",
      "Epoch 11/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0761\n",
      "Epoch 12/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0739\n",
      "Epoch 13/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0643\n",
      "Epoch 14/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0535\n",
      "Epoch 15/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0594\n",
      "Epoch 16/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0625\n",
      "Epoch 17/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0584\n",
      "Epoch 18/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0480\n",
      "Epoch 19/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0463\n",
      "Epoch 20/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0585\n",
      "Epoch 21/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0533\n",
      "Epoch 22/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0492\n",
      "Epoch 23/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0423\n",
      "Epoch 24/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0463\n",
      "Epoch 25/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0452\n",
      "Epoch 26/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0482\n",
      "Epoch 27/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0418\n",
      "Epoch 28/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0402\n",
      "Epoch 29/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0484\n",
      "Epoch 30/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0470\n",
      "Epoch 31/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0427\n",
      "Epoch 32/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0428\n",
      "Epoch 33/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0385\n",
      "Epoch 34/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0358\n",
      "Epoch 35/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0433\n",
      "Epoch 36/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0399\n",
      "Epoch 37/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0414\n",
      "Epoch 38/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0401\n",
      "Epoch 39/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0408\n",
      "Epoch 40/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0489\n",
      "Epoch 41/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0389\n",
      "Epoch 42/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0399\n",
      "Epoch 43/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0328\n",
      "Epoch 44/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0337\n",
      "Epoch 45/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0376\n",
      "Epoch 46/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0322\n",
      "Epoch 47/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0356\n",
      "Epoch 48/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0326\n",
      "Epoch 49/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0297\n",
      "Epoch 50/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0315\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0842\n",
      "Epoch 1/50\n",
      "160/160 [==============================] - 1s 2ms/step - loss: 1.1053\n",
      "Epoch 2/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.7191\n",
      "Epoch 3/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.5669\n",
      "Epoch 4/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.4842\n",
      "Epoch 5/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.3204\n",
      "Epoch 6/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.2699\n",
      "Epoch 7/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1894\n",
      "Epoch 8/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1445\n",
      "Epoch 9/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0963\n",
      "Epoch 10/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0793\n",
      "Epoch 11/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0767\n",
      "Epoch 12/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0739\n",
      "Epoch 13/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0567\n",
      "Epoch 14/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0568\n",
      "Epoch 15/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0543\n",
      "Epoch 16/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0581\n",
      "Epoch 17/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0575\n",
      "Epoch 18/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0683\n",
      "Epoch 19/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0549\n",
      "Epoch 20/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0462\n",
      "Epoch 21/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0470\n",
      "Epoch 22/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0424\n",
      "Epoch 23/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0454\n",
      "Epoch 24/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0464\n",
      "Epoch 25/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0446\n",
      "Epoch 26/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0437\n",
      "Epoch 27/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0524\n",
      "Epoch 28/50\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0517\n",
      "Epoch 29/50\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0435\n",
      "Epoch 30/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0398\n",
      "Epoch 31/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0394\n",
      "Epoch 32/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0401\n",
      "Epoch 33/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0378\n",
      "Epoch 34/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0421\n",
      "Epoch 35/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0373\n",
      "Epoch 36/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0413\n",
      "Epoch 37/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0338\n",
      "Epoch 38/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0379\n",
      "Epoch 39/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0327\n",
      "Epoch 40/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0342\n",
      "Epoch 41/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0354\n",
      "Epoch 42/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0382\n",
      "Epoch 43/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0323\n",
      "Epoch 44/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0366\n",
      "Epoch 45/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0372\n",
      "Epoch 46/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0331\n",
      "Epoch 47/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0355\n",
      "Epoch 48/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0326\n",
      "Epoch 49/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0296\n",
      "Epoch 50/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0340\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.2123\n",
      "Epoch 1/50\n",
      "160/160 [==============================] - 1s 2ms/step - loss: 1.0716\n",
      "Epoch 2/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.7096\n",
      "Epoch 3/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.6249\n",
      "Epoch 4/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.4736\n",
      "Epoch 5/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.3167\n",
      "Epoch 6/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.2544\n",
      "Epoch 7/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1853\n",
      "Epoch 8/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1315\n",
      "Epoch 9/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0953\n",
      "Epoch 10/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0832\n",
      "Epoch 11/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0844\n",
      "Epoch 12/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0827\n",
      "Epoch 13/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0666\n",
      "Epoch 14/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0638\n",
      "Epoch 15/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0567\n",
      "Epoch 16/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0611\n",
      "Epoch 17/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0586\n",
      "Epoch 18/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0635\n",
      "Epoch 19/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0540\n",
      "Epoch 20/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0520\n",
      "Epoch 21/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0502\n",
      "Epoch 22/50\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0562\n",
      "Epoch 23/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0527\n",
      "Epoch 24/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0516\n",
      "Epoch 25/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0493\n",
      "Epoch 26/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0507\n",
      "Epoch 27/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0573\n",
      "Epoch 28/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0458\n",
      "Epoch 29/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0532\n",
      "Epoch 30/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0414\n",
      "Epoch 31/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0401\n",
      "Epoch 32/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0477\n",
      "Epoch 33/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0398\n",
      "Epoch 34/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0465\n",
      "Epoch 35/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0414\n",
      "Epoch 36/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0376\n",
      "Epoch 37/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0380\n",
      "Epoch 38/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0370\n",
      "Epoch 39/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0397\n",
      "Epoch 40/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0356\n",
      "Epoch 41/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0327\n",
      "Epoch 42/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0372\n",
      "Epoch 43/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0384\n",
      "Epoch 44/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0387\n",
      "Epoch 45/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0327\n",
      "Epoch 46/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0330\n",
      "Epoch 47/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0418\n",
      "Epoch 48/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0331\n",
      "Epoch 49/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0367\n",
      "Epoch 50/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0346\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.1957\n",
      "Epoch 1/50\n",
      "160/160 [==============================] - 1s 2ms/step - loss: 1.1457\n",
      "Epoch 2/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.7158\n",
      "Epoch 3/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.6511\n",
      "Epoch 4/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.4958\n",
      "Epoch 5/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.3862\n",
      "Epoch 6/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.2413\n",
      "Epoch 7/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.2041\n",
      "Epoch 8/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1338\n",
      "Epoch 9/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1089\n",
      "Epoch 10/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0803\n",
      "Epoch 11/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0736\n",
      "Epoch 12/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0752\n",
      "Epoch 13/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0747\n",
      "Epoch 14/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0578\n",
      "Epoch 15/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0534\n",
      "Epoch 16/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0528\n",
      "Epoch 17/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0586\n",
      "Epoch 18/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0567\n",
      "Epoch 19/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0507\n",
      "Epoch 20/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0501\n",
      "Epoch 21/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0452\n",
      "Epoch 22/50\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0532\n",
      "Epoch 23/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0517\n",
      "Epoch 24/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0498\n",
      "Epoch 25/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0416\n",
      "Epoch 26/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0524\n",
      "Epoch 27/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0478\n",
      "Epoch 28/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0459\n",
      "Epoch 29/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0417\n",
      "Epoch 30/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0397\n",
      "Epoch 31/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0446\n",
      "Epoch 32/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0409\n",
      "Epoch 33/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0453\n",
      "Epoch 34/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0436\n",
      "Epoch 35/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0385\n",
      "Epoch 36/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0399\n",
      "Epoch 37/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0367\n",
      "Epoch 38/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0347\n",
      "Epoch 39/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0344\n",
      "Epoch 40/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0353\n",
      "Epoch 41/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0349\n",
      "Epoch 42/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0339\n",
      "Epoch 43/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0377\n",
      "Epoch 44/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0367\n",
      "Epoch 45/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0340\n",
      "Epoch 46/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0339\n",
      "Epoch 47/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0302\n",
      "Epoch 48/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0345\n",
      "Epoch 49/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0321\n",
      "Epoch 50/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0346\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0038\n",
      "Epoch 1/50\n",
      "160/160 [==============================] - 1s 2ms/step - loss: 1.1339\n",
      "Epoch 2/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.7570\n",
      "Epoch 3/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.6286\n",
      "Epoch 4/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.4580\n",
      "Epoch 5/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.3369\n",
      "Epoch 6/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.2370\n",
      "Epoch 7/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1791\n",
      "Epoch 8/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1121\n",
      "Epoch 9/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1058\n",
      "Epoch 10/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0804\n",
      "Epoch 11/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0721\n",
      "Epoch 12/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0703\n",
      "Epoch 13/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0627\n",
      "Epoch 14/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0640\n",
      "Epoch 15/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0503\n",
      "Epoch 16/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0632\n",
      "Epoch 17/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0572\n",
      "Epoch 18/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0543\n",
      "Epoch 19/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0501\n",
      "Epoch 20/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0491\n",
      "Epoch 21/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0514\n",
      "Epoch 22/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0412\n",
      "Epoch 23/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0439\n",
      "Epoch 24/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0485\n",
      "Epoch 25/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0483\n",
      "Epoch 26/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0489\n",
      "Epoch 27/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0422\n",
      "Epoch 28/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0421\n",
      "Epoch 29/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0426\n",
      "Epoch 30/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0457\n",
      "Epoch 31/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0439\n",
      "Epoch 32/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0414\n",
      "Epoch 33/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0491\n",
      "Epoch 34/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0487\n",
      "Epoch 35/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0372\n",
      "Epoch 36/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0358\n",
      "Epoch 37/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0392\n",
      "Epoch 38/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0384\n",
      "Epoch 39/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0357\n",
      "Epoch 40/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0355\n",
      "Epoch 41/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0365\n",
      "Epoch 42/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0365\n",
      "Epoch 43/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0383\n",
      "Epoch 44/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0407\n",
      "Epoch 45/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0285\n",
      "Epoch 46/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0360\n",
      "Epoch 47/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0325\n",
      "Epoch 48/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0364\n",
      "Epoch 49/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0332\n",
      "Epoch 50/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0312\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0636\n",
      "Epoch 1/50\n",
      "160/160 [==============================] - 1s 2ms/step - loss: 1.0489\n",
      "Epoch 2/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.7217\n",
      "Epoch 3/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.6123\n",
      "Epoch 4/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.5016\n",
      "Epoch 5/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.3600\n",
      "Epoch 6/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.2623\n",
      "Epoch 7/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1819\n",
      "Epoch 8/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1454\n",
      "Epoch 9/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0986\n",
      "Epoch 10/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0905\n",
      "Epoch 11/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0768\n",
      "Epoch 12/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0808\n",
      "Epoch 13/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0661\n",
      "Epoch 14/50\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0638\n",
      "Epoch 15/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0596\n",
      "Epoch 16/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0601\n",
      "Epoch 17/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0488\n",
      "Epoch 18/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0553\n",
      "Epoch 19/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0517\n",
      "Epoch 20/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0469\n",
      "Epoch 21/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0549\n",
      "Epoch 22/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0475\n",
      "Epoch 23/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0468\n",
      "Epoch 24/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0495\n",
      "Epoch 25/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0462\n",
      "Epoch 26/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0515\n",
      "Epoch 27/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0511\n",
      "Epoch 28/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0471\n",
      "Epoch 29/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0434\n",
      "Epoch 30/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0490\n",
      "Epoch 31/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0434\n",
      "Epoch 32/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0477\n",
      "Epoch 33/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0444\n",
      "Epoch 34/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0417\n",
      "Epoch 35/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0441\n",
      "Epoch 36/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0444\n",
      "Epoch 37/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0350\n",
      "Epoch 38/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0427\n",
      "Epoch 39/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0370\n",
      "Epoch 40/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0385\n",
      "Epoch 41/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0418\n",
      "Epoch 42/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0406\n",
      "Epoch 43/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0400\n",
      "Epoch 44/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0339\n",
      "Epoch 45/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0329\n",
      "Epoch 46/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0331\n",
      "Epoch 47/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0356\n",
      "Epoch 48/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0343\n",
      "Epoch 49/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0390\n",
      "Epoch 50/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0373\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0044\n",
      "Epoch 1/50\n",
      "160/160 [==============================] - 1s 2ms/step - loss: 1.0885\n",
      "Epoch 2/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.7189\n",
      "Epoch 3/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.6267\n",
      "Epoch 4/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.4916\n",
      "Epoch 5/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.3803\n",
      "Epoch 6/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.2325\n",
      "Epoch 7/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1777\n",
      "Epoch 8/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1256\n",
      "Epoch 9/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1234\n",
      "Epoch 10/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1148\n",
      "Epoch 11/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0830\n",
      "Epoch 12/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0765\n",
      "Epoch 13/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0673\n",
      "Epoch 14/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0609\n",
      "Epoch 15/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0721\n",
      "Epoch 16/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0623\n",
      "Epoch 17/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0593\n",
      "Epoch 18/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0551\n",
      "Epoch 19/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0546\n",
      "Epoch 20/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0486\n",
      "Epoch 21/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0517\n",
      "Epoch 22/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0444\n",
      "Epoch 23/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0550\n",
      "Epoch 24/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0581\n",
      "Epoch 25/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0443\n",
      "Epoch 26/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0583\n",
      "Epoch 27/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0475\n",
      "Epoch 28/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0459\n",
      "Epoch 29/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0484\n",
      "Epoch 30/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0457\n",
      "Epoch 31/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0419\n",
      "Epoch 32/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0376\n",
      "Epoch 33/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0438\n",
      "Epoch 34/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0410\n",
      "Epoch 35/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0370\n",
      "Epoch 36/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0452\n",
      "Epoch 37/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0400\n",
      "Epoch 38/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0404\n",
      "Epoch 39/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0386\n",
      "Epoch 40/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0414\n",
      "Epoch 41/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0376\n",
      "Epoch 42/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0353\n",
      "Epoch 43/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0340\n",
      "Epoch 44/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0358\n",
      "Epoch 45/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0334\n",
      "Epoch 46/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0331\n",
      "Epoch 47/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0422\n",
      "Epoch 48/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0376\n",
      "Epoch 49/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0343\n",
      "Epoch 50/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0351\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0892\n",
      "Epoch 1/50\n",
      "160/160 [==============================] - 1s 2ms/step - loss: 1.1355\n",
      "Epoch 2/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.7722\n",
      "Epoch 3/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.6629\n",
      "Epoch 4/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.5390\n",
      "Epoch 5/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.4094\n",
      "Epoch 6/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.2581\n",
      "Epoch 7/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1900\n",
      "Epoch 8/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1510\n",
      "Epoch 9/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1167\n",
      "Epoch 10/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0929\n",
      "Epoch 11/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0942\n",
      "Epoch 12/50\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0747\n",
      "Epoch 13/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0746\n",
      "Epoch 14/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0728\n",
      "Epoch 15/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0702\n",
      "Epoch 16/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0631\n",
      "Epoch 17/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0568\n",
      "Epoch 18/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0580\n",
      "Epoch 19/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0564\n",
      "Epoch 20/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0509\n",
      "Epoch 21/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0524\n",
      "Epoch 22/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0546\n",
      "Epoch 23/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0619\n",
      "Epoch 24/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0589\n",
      "Epoch 25/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0484\n",
      "Epoch 26/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0468\n",
      "Epoch 27/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0499\n",
      "Epoch 28/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0493\n",
      "Epoch 29/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0461\n",
      "Epoch 30/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0485\n",
      "Epoch 31/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0449\n",
      "Epoch 32/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0464\n",
      "Epoch 33/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0441\n",
      "Epoch 34/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0458\n",
      "Epoch 35/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0469\n",
      "Epoch 36/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0404\n",
      "Epoch 37/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0397\n",
      "Epoch 38/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0434\n",
      "Epoch 39/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0428\n",
      "Epoch 40/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0432\n",
      "Epoch 41/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0430\n",
      "Epoch 42/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0351\n",
      "Epoch 43/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0369\n",
      "Epoch 44/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0407\n",
      "Epoch 45/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0365\n",
      "Epoch 46/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0377\n",
      "Epoch 47/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0364\n",
      "Epoch 48/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0316\n",
      "Epoch 49/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0313\n",
      "Epoch 50/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0350\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.7430\n",
      "Epoch 1/50\n",
      "160/160 [==============================] - 1s 2ms/step - loss: 1.0659\n",
      "Epoch 2/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.7699\n",
      "Epoch 3/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.6495\n",
      "Epoch 4/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.4870\n",
      "Epoch 5/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.3637\n",
      "Epoch 6/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.2392\n",
      "Epoch 7/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1742\n",
      "Epoch 8/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1233\n",
      "Epoch 9/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0932\n",
      "Epoch 10/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0839\n",
      "Epoch 11/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0715\n",
      "Epoch 12/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0752\n",
      "Epoch 13/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0600\n",
      "Epoch 14/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0587\n",
      "Epoch 15/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0592\n",
      "Epoch 16/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0693\n",
      "Epoch 17/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0530\n",
      "Epoch 18/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0562\n",
      "Epoch 19/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0498\n",
      "Epoch 20/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0519\n",
      "Epoch 21/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0570\n",
      "Epoch 22/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0561\n",
      "Epoch 23/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0645\n",
      "Epoch 24/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0495\n",
      "Epoch 25/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0421\n",
      "Epoch 26/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0475\n",
      "Epoch 27/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0421\n",
      "Epoch 28/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0455\n",
      "Epoch 29/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0438\n",
      "Epoch 30/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0355\n",
      "Epoch 31/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0443\n",
      "Epoch 32/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0448\n",
      "Epoch 33/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0443\n",
      "Epoch 34/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0445\n",
      "Epoch 35/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0422\n",
      "Epoch 36/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0368\n",
      "Epoch 37/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0326\n",
      "Epoch 38/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0381\n",
      "Epoch 39/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0364\n",
      "Epoch 40/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0333\n",
      "Epoch 41/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0444\n",
      "Epoch 42/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0366\n",
      "Epoch 43/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0329\n",
      "Epoch 44/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0384\n",
      "Epoch 45/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0344\n",
      "Epoch 46/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0308\n",
      "Epoch 47/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0356\n",
      "Epoch 48/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0381\n",
      "Epoch 49/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0341\n",
      "Epoch 50/50\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0362\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 1.0556\n",
      "-1.0260768055915832\n",
      "The mean accuracy: -1.0260768055915832\n"
     ]
    }
   ],
   "source": [
    "# Create a KerasClassifier with best parameters\n",
    "model_KR = KerasRegressor(build_fn = create_model, batch_size = 16, epochs = 50)\n",
    "\n",
    "# Calculate the accuracy score for each fold\n",
    "kfolds = cross_val_score(model_KR, x_full, Y_full, cv = 10)\n",
    "\n",
    "#get the accuracy\n",
    "print(kfolds.mean())\n",
    "print('The mean accuracy:', kfolds.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e284a2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T07:17:33.646501Z",
     "iopub.status.busy": "2021-08-01T07:17:33.645616Z",
     "iopub.status.idle": "2021-08-01T07:17:33.648611Z",
     "shell.execute_reply": "2021-08-01T07:17:33.648149Z",
     "shell.execute_reply.started": "2021-08-01T07:10:53.515569Z"
    },
    "papermill": {
     "duration": 0.953878,
     "end_time": "2021-08-01T07:17:33.648748",
     "exception": false,
     "start_time": "2021-08-01T07:17:32.694870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#use callbacks\n",
    "from keras.callbacks import Callback, ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"\", monitor=\"val_loss\", verbose=1, save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=5, min_lr=1e-6, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=5, mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af6f7fa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T07:17:35.517782Z",
     "iopub.status.busy": "2021-08-01T07:17:35.516788Z",
     "iopub.status.idle": "2021-08-01T07:17:55.324073Z",
     "shell.execute_reply": "2021-08-01T07:17:55.323471Z",
     "shell.execute_reply.started": "2021-08-01T07:10:53.524271Z"
    },
    "papermill": {
     "duration": 20.740552,
     "end_time": "2021-08-01T07:17:55.324223",
     "exception": false,
     "start_time": "2021-08-01T07:17:34.583671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "107/107 [==============================] - 1s 8ms/step - loss: 1.1340 - val_loss: 0.8850\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.88503, saving model to \n",
      "Epoch 2/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.7557 - val_loss: 0.8632\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.88503 to 0.86315, saving model to \n",
      "Epoch 3/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.6572 - val_loss: 0.8646\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.86315\n",
      "Epoch 4/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.4971 - val_loss: 0.9377\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.86315\n",
      "Epoch 5/50\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.3412 - val_loss: 0.9661\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.86315\n",
      "Epoch 6/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2404 - val_loss: 0.9760\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.86315\n",
      "Epoch 7/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.2119 - val_loss: 0.9833\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.86315\n",
      "Epoch 8/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1520 - val_loss: 0.9988\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.86315\n",
      "Epoch 9/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0995 - val_loss: 0.9977\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.86315\n",
      "Epoch 10/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.1001 - val_loss: 0.9889\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.86315\n",
      "Epoch 11/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0839 - val_loss: 0.9760\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.86315\n",
      "Epoch 12/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0791 - val_loss: 0.9719\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.86315\n",
      "Epoch 13/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0695 - val_loss: 0.9944\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.86315\n",
      "Epoch 14/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0573 - val_loss: 0.9581\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.86315\n",
      "Epoch 15/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0466 - val_loss: 0.9702\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.86315\n",
      "Epoch 16/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0541 - val_loss: 0.9737\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.86315\n",
      "Epoch 17/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0606 - val_loss: 0.9567\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.86315\n",
      "Epoch 18/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0544 - val_loss: 0.9573\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.86315\n",
      "Epoch 19/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0491 - val_loss: 0.9621\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.86315\n",
      "Epoch 20/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0543 - val_loss: 0.9587\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.86315\n",
      "Epoch 21/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0506 - val_loss: 0.9434\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.86315\n",
      "Epoch 22/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0461 - val_loss: 0.9626\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.86315\n",
      "Epoch 23/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0548 - val_loss: 0.9654\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.86315\n",
      "Epoch 24/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0544 - val_loss: 0.9564\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.86315\n",
      "Epoch 25/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0472 - val_loss: 0.9570\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.86315\n",
      "Epoch 26/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0444 - val_loss: 0.9653\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.86315\n",
      "Epoch 27/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0421 - val_loss: 0.9451\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.86315\n",
      "Epoch 28/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0384 - val_loss: 0.9366\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.86315\n",
      "Epoch 29/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0410 - val_loss: 0.9613\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.86315\n",
      "Epoch 30/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0431 - val_loss: 0.9547\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.86315\n",
      "Epoch 31/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0433 - val_loss: 0.9459\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.86315\n",
      "Epoch 32/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0400 - val_loss: 0.9363\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.86315\n",
      "Epoch 33/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0399 - val_loss: 0.9582\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.86315\n",
      "Epoch 34/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0399 - val_loss: 0.9533\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.86315\n",
      "Epoch 35/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0345 - val_loss: 0.9657\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.86315\n",
      "Epoch 36/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0368 - val_loss: 0.9553\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.86315\n",
      "Epoch 37/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0424 - val_loss: 0.9383\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.86315\n",
      "Epoch 38/50\n",
      "107/107 [==============================] - 0s 4ms/step - loss: 0.0387 - val_loss: 0.9477\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.86315\n",
      "Epoch 39/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0354 - val_loss: 0.9152\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.86315\n",
      "Epoch 40/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0399 - val_loss: 0.9621\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.86315\n",
      "Epoch 41/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0364 - val_loss: 0.9575\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.86315\n",
      "Epoch 42/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0385 - val_loss: 0.9549\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.86315\n",
      "Epoch 43/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0366 - val_loss: 0.9474\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.86315\n",
      "Epoch 44/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.9390\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.86315\n",
      "Epoch 45/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0334 - val_loss: 0.9288\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.86315\n",
      "Epoch 46/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0332 - val_loss: 0.9468\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.86315\n",
      "Epoch 47/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0351 - val_loss: 0.9445\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.86315\n",
      "Epoch 48/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0343 - val_loss: 0.9534\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.86315\n",
      "Epoch 49/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0461 - val_loss: 0.9386\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.86315\n",
      "Epoch 50/50\n",
      "107/107 [==============================] - 0s 3ms/step - loss: 0.0397 - val_loss: 0.9619\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.86315\n"
     ]
    }
   ],
   "source": [
    "history = model_KR.fit(\n",
    "    x_full, Y_full,\n",
    "    validation_split=0.4,\n",
    "    batch_size=16,\n",
    "    epochs=50,\n",
    "    callbacks = [early_stop, checkpoint, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba418de5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T07:17:57.335624Z",
     "iopub.status.busy": "2021-08-01T07:17:57.334996Z",
     "iopub.status.idle": "2021-08-01T07:17:57.550207Z",
     "shell.execute_reply": "2021-08-01T07:17:57.550653Z",
     "shell.execute_reply.started": "2021-08-01T07:11:15.796630Z"
    },
    "papermill": {
     "duration": 1.218056,
     "end_time": "2021-08-01T07:17:57.550825",
     "exception": false,
     "start_time": "2021-08-01T07:17:56.332769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[1:, ['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fa79a5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T07:17:59.568578Z",
     "iopub.status.busy": "2021-08-01T07:17:59.567634Z",
     "iopub.status.idle": "2021-08-01T07:17:59.570518Z",
     "shell.execute_reply": "2021-08-01T07:17:59.569959Z",
     "shell.execute_reply.started": "2021-08-01T07:11:15.998099Z"
    },
    "papermill": {
     "duration": 1.033397,
     "end_time": "2021-08-01T07:17:59.570649",
     "exception": false,
     "start_time": "2021-08-01T07:17:58.537252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a03cab8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T07:18:01.577274Z",
     "iopub.status.busy": "2021-08-01T07:18:01.576237Z",
     "iopub.status.idle": "2021-08-01T07:18:01.580772Z",
     "shell.execute_reply": "2021-08-01T07:18:01.580257Z",
     "shell.execute_reply.started": "2021-08-01T07:11:16.006913Z"
    },
    "papermill": {
     "duration": 1.017014,
     "end_time": "2021-08-01T07:18:01.580921",
     "exception": false,
     "start_time": "2021-08-01T07:18:00.563907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.976763</td>\n",
       "      <td>0.885032</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.751776</td>\n",
       "      <td>0.863152</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.654570</td>\n",
       "      <td>0.864562</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.507667</td>\n",
       "      <td>0.937705</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.349907</td>\n",
       "      <td>0.966075</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  val_loss     lr\n",
       "0  0.976763  0.885032  0.001\n",
       "1  0.751776  0.863152  0.001\n",
       "2  0.654570  0.864562  0.001\n",
       "3  0.507667  0.937705  0.001\n",
       "4  0.349907  0.966075  0.001"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "603c7ab7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T07:18:03.609356Z",
     "iopub.status.busy": "2021-08-01T07:18:03.608780Z",
     "iopub.status.idle": "2021-08-01T07:18:03.719068Z",
     "shell.execute_reply": "2021-08-01T07:18:03.718405Z",
     "shell.execute_reply.started": "2021-08-01T07:13:14.600008Z"
    },
    "papermill": {
     "duration": 1.110536,
     "end_time": "2021-08-01T07:18:03.719208",
     "exception": false,
     "start_time": "2021-08-01T07:18:02.608672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predict \n",
    "pred_test = model_KR.predict(final_test_vector)\n",
    "pred_test_list = [i for i in pred_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbc8808d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-01T07:18:05.756553Z",
     "iopub.status.busy": "2021-08-01T07:18:05.755608Z",
     "iopub.status.idle": "2021-08-01T07:18:05.767670Z",
     "shell.execute_reply": "2021-08-01T07:18:05.766972Z",
     "shell.execute_reply.started": "2021-08-01T07:13:23.321984Z"
    },
    "papermill": {
     "duration": 1.007214,
     "end_time": "2021-08-01T07:18:05.767826",
     "exception": false,
     "start_time": "2021-08-01T07:18:04.760612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f722661</td>\n",
       "      <td>-1.420358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f0953f0a5</td>\n",
       "      <td>-1.254530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0df072751</td>\n",
       "      <td>-1.127209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04caf4e0c</td>\n",
       "      <td>-2.504905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e63f8bea</td>\n",
       "      <td>-2.361248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12537fe78</td>\n",
       "      <td>-0.328222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>965e592c0</td>\n",
       "      <td>0.109890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    target\n",
       "0  c0f722661 -1.420358\n",
       "1  f0953f0a5 -1.254530\n",
       "2  0df072751 -1.127209\n",
       "3  04caf4e0c -2.504905\n",
       "4  0e63f8bea -2.361248\n",
       "5  12537fe78 -0.328222\n",
       "6  965e592c0  0.109890"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create submission file\n",
    "submission = pd.DataFrame({'id' : test_data['id'], 'target' : pred_test_list})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 225.929025,
   "end_time": "2021-08-01T07:18:08.868034",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-01T07:14:22.939009",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
